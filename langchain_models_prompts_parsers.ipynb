{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNIkj318sUFPdYCSj0RRQJz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gayashan4lk/langchain-for-app-development/blob/main/langchain_models_prompts_parsers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Langchain: Models, Prompts and Output Parsers"
      ],
      "metadata": {
        "id": "LJbx3n9h4cSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "nND1_b6d4mKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Direct API Calls to OpenAI"
      ],
      "metadata": {
        "id": "Iz9_akcz4uLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHIbpztrs0vz",
        "outputId": "6d2e93cd-f5ec-4037-f6e7-2f6e50f291a0",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "# print(api_key)\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "# print(os.environ[\"OPENAI_API_KEY\"])"
      ],
      "metadata": {
        "id": "3_C3L_5cs3Ge"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-5-nano\",\n",
        "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
        ")"
      ],
      "metadata": {
        "id": "N_vWTCeNwQuD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.output_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ZZA1nPJq4Bw1",
        "outputId": "de13da93-2da1-45c8-c6c0-ca23baac1d13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In a moonlit meadow, a gentle silver unicorn curled beside a sleeping brook and whispered a lullaby to the stars until the night drifted into dreams.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-5-nano\"):\n",
        "  response = client.responses.create(\n",
        "      model=model,\n",
        "      input=prompt\n",
        "  )\n",
        "  return response.output_text\n"
      ],
      "metadata": {
        "id": "TJCvbE83y-Iq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_completion(\"what is 1+1?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xjBd73fmzySB",
        "outputId": "1a063fc5-2760-467a-fa8d-151fcbc38a48"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2 (in decimal). If you’re thinking in binary, 1 + 1 = 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_email = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse,\\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UOAi57Lr0WBC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gzEIt2TZ2i2Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"Translate the text \\\n",
        "that is delimited by triple backticks\n",
        "into a style that is {style}.\n",
        "text: ```{customer_email}```\n",
        "\"\"\"\n",
        "\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5Oi14oV2tGt",
        "outputId": "c3910a97-54fe-406c-8ad0-c58bf288a7fe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translate the text that is delimited by triple backticks\n",
            "into a style that is American English in a calm and respectful tone\n",
            ".\n",
            "text: ```\n",
            "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
            "```\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = get_completion(prompt)"
      ],
      "metadata": {
        "id": "FvqcIyfd2vEV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "0y6t2hHX3nki",
        "outputId": "f7e8cd37-9312-45ad-d41d-4756f2bd7743"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm quite frustrated that the blender lid came off and splattered smoothie onto my kitchen walls. To make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I would appreciate your help with this as soon as possible.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API calls through LangChain"
      ],
      "metadata": {
        "id": "H7Qldndz6CJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U \"langchain[openai]\""
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfzeZk-Z6JIy",
        "outputId": "97af1ed5-4841-4a8a-b7c8-760c23c15b83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain[openai] in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain[openai]\n",
            "  Downloading langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.4 (from langchain[openai])\n",
            "  Downloading langchain_core-1.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting langgraph<1.1.0,>=1.0.2 (from langchain[openai])\n",
            "  Downloading langgraph-1.0.3-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain[openai]) (2.11.10)\n",
            "Collecting langchain-openai (from langchain[openai])\n",
            "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain[openai]) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain[openai]) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain[openai]) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain[openai]) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain[openai]) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.4->langchain[openai]) (4.15.0)\n",
            "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph<1.1.0,>=1.0.2->langchain[openai])\n",
            "  Downloading langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph<1.1.0,>=1.0.2->langchain[openai])\n",
            "  Downloading langgraph_prebuilt-1.0.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph<1.1.0,>=1.0.2->langchain[openai])\n",
            "  Downloading langgraph_sdk-0.2.9-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[openai]) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.4.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->langchain[openai]) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->langchain[openai]) (0.12.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.4->langchain[openai]) (3.0.0)\n",
            "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain[openai])\n",
            "  Downloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain[openai]) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain[openai]) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain[openai]) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai->langchain[openai]) (2024.11.6)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai->langchain[openai]) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[openai]) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain[openai]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.4->langchain[openai]) (2.5.0)\n",
            "Downloading langchain_core-1.0.5-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.5/471.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-1.0.3-py3-none-any.whl (156 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-1.0.7-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.7/93.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.0.3-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-1.0.4-py3-none-any.whl (34 kB)\n",
            "Downloading langgraph_sdk-0.2.9-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.3/208.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.79\n",
            "    Uninstalling langchain-core-0.3.79:\n",
            "      Successfully uninstalled langchain-core-0.3.79\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "Successfully installed langchain-1.0.7 langchain-core-1.0.5 langchain-openai-1.0.3 langgraph-1.0.3 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.4 langgraph-sdk-0.2.9 ormsgpack-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "gpt_5_nano = init_chat_model(model=\"gpt-5-nano\", temperature=0.0)\n",
        "response = gpt_5_nano.invoke(\"Why do parrots talk?\")"
      ],
      "metadata": {
        "id": "YSSU1SJu7DY5"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL17_4pF7fZ4",
        "outputId": "f3cf3b9d-64c1-47a4-aa5f-057ef46146cf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Parrots talk because they’re highly social, highly intelligent vocal learners. They mimic the sounds they hear—whether other birds or people—and use those sounds to communicate with their group. In the wild, this helps them stay with their flock and coordinate calls; in captivity, they often imitate humans because we reward them with attention, treats, or play.\\n\\nKey points:\\n- They aren’t “saying” words the way people do; they’re imitating sounds they’ve heard and learned through repetition and reinforcement.\\n- Some parrots seem to use words in context and with intention, but most are mainly reproducing sounds they’ve heard.\\n- Different species vary a lot: some (like African greys and amazons) are especially famous for talking, while others may not talk much or at all.\\n- Their brains have specialized circuits that support complex vocal learning, which is part of what makes them such capable imitators.\\n\\nIf you’d like, I can share tips on encouraging a parrot to talk or explain which species tends to talk more.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1755, 'prompt_tokens': 12, 'total_tokens': 1767, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 1536, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CcT4A9oLCDzfe8ObccKJEluI6vxD9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--c2810348-e221-4409-aa9a-88868b757dfd-0', usage_metadata={'input_tokens': 12, 'output_tokens': 1755, 'total_tokens': 1767, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 1536}})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "WekiY0x-7acR",
        "outputId": "a025d3e3-0d88-4fc4-9053-43bf0dc5eaf8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Parrots talk mainly because they are vocal learners and very social birds. In the wild, their calls help them stay with the flock, warn others, attract mates, and communicate over distances. Domesticated parrots hear lots of human speech, so many learn to imitate those sounds as part of fitting in with their human “flock.” They don’t just copy words for fun—they’re also seeking attention, companionship, and sometimes rewards (pets, treats, or more interaction).\\n\\nKey points:\\n- Not all parrots talk, and some species are naturally better at mimicry than others (e.g., African greys and some Amazons are well-known talkers; others may whistle or chirp more).\\n- They imitate sounds they hear often and in meaningful contexts (often paired with a person’s reactions, routines, or routines like mealtime).\\n- They understand language to a limited extent. They may associate a word with a behavior or object, but they don’t “understand” language the way people do.\\n\\nIf you want a parrot to talk more, try these tips:\\n- Spend short, consistent daily sessions (a few minutes each day).\\n- Choose a small set of simple phrases and use them in the same context (e.g., “Hello!” when you enter the room, “wanna cracker?” during snack time).\\n- Reinforce with positive reactions (eye contact, praise, or a treat) when they attempt to say the word.\\n- Keep training fun and not frustrated; avoid scolding or forcing phrases.\\n- Provide enrichment and interaction beyond talking (toys, puzzles, daily bonding time) so talking isn’t their only stimulus.\\n\\nIf you’d like, tell me your parrot’s species and age, and I can tailor tips for teaching them to talk or suggest appropriate phrases.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(response)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "QndPBnqL7snT",
        "outputId": "49c51914-6bc9-4b0c-eda6-316d873277ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.messages.ai.AIMessage"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.messages.ai.AIMessage</b><br/>def __init__(content: str | list[str | dict] | None=None, content_blocks: list[types.ContentBlock] | None=None, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/messages/ai.py</a>Message from an AI.\n",
              "\n",
              "An `AIMessage` is returned from a chat model as a response to a prompt.\n",
              "\n",
              "This message represents the output of the model and consists of both\n",
              "the raw output as returned by the model and standardized fields\n",
              "(e.g., tool calls, usage metadata) added by the LangChain framework.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 153);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF3ga5fW8G3J",
        "outputId": "4d533b6e-0a23-468f-afaa-4a8d534afd6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompts"
      ],
      "metadata": {
        "id": "FqJ8cFatHSgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Templates"
      ],
      "metadata": {
        "id": "UJGoMhmK_-k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain_core"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yse7Ykkw__jq",
        "outputId": "eb4d21af-1713-4287-d941-b517e8b96cfe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.12/dist-packages (1.0.5)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (0.4.42)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (4.15.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_core) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "template_string = \"\"\"Translate the text \\\n",
        "that is delimited by triple backticks \\\n",
        "into a style that is {style}. \\\n",
        "text: ```{text}```\n",
        "\"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)"
      ],
      "metadata": {
        "id": "ATYm-s9nANhi"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(prompt_template.messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDkBCMlgAWus",
        "outputId": "539eb044-6136-4f3f-d967-8cb01fddde4a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJuAvAi5BQST",
        "outputId": "4a1e0f68-60ac-477e-de02-baa68b86bf42"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n'), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0].prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksNuJn3SBTDE",
        "outputId": "a8113a3b-2125-48a3-b1e8-32a10010b3db"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['style', 'text'], input_types={}, partial_variables={}, template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template.messages[0].prompt.input_variables"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cc9m-pbBaeO",
        "outputId": "100c2769-18b6-47e3-919e-818d3fe27fe3"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['style', 'text']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_style = \"\"\"American English \\\n",
        "in a calm and respectful tone\n",
        "\"\"\"\n",
        "\n",
        "customer_message_content = \"\"\"\n",
        "Arrr, I be fuming that me blender lid \\\n",
        "flew off and splattered me kitchen walls \\\n",
        "with smoothie! And to make matters worse, \\\n",
        "the warranty don't cover the cost of \\\n",
        "cleaning up me kitchen. I need yer help \\\n",
        "right now, matey!\n",
        "\"\"\"\n",
        "\n",
        "customer_message = prompt_template.format(\n",
        "    style=customer_style,\n",
        "    text=customer_message_content\n",
        ")"
      ],
      "metadata": {
        "id": "Kw8ry0kXBead"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(customer_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDk1W04oCT2H",
        "outputId": "dde31fd4-29ae-4d1e-a0fd-0166e31b8893"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "1mluMbWfChWb",
        "outputId": "588f2132-6db4-4c93-c422-40a29cad9da4"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Human: Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone\\n. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt_5_nano.invoke(customer_message)\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6gfy4G_UCi4e",
        "outputId": "0c9ad911-cf2d-49e4-ee46-d81911676d75"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm frustrated that the blender lid flew off and splattered smoothie on my kitchen walls. To make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I would appreciate your prompt assistance with this.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_style = \"\"\"\\\n",
        "a polite tone \\\n",
        "that speaks in English Pirate\\\n",
        "\"\"\"\n",
        "\n",
        "service_message_content = \"\"\"Hey there customer, \\\n",
        "the warranty does not cover \\\n",
        "cleaning expenses for your kitchen \\\n",
        "because it's your fault that \\\n",
        "you misused your blender \\\n",
        "by forgetting to put the lid on before \\\n",
        "starting the blender. \\\n",
        "Tough luck! See ya!\n",
        "\"\"\"\n",
        "\n",
        "service_message = prompt_template.format(\n",
        "    style=service_style,\n",
        "    text=service_message_content\n",
        ")"
      ],
      "metadata": {
        "id": "ACflxWmfDPmS"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(service_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLbv6h-EEn3E",
        "outputId": "9c954f85-b442-4496-f52c-f4172fa2daa9"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "service_message"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "ptYv2emMFJwb",
        "outputId": "96955630-67bd-422d-80dc-3732e67e9678"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Human: Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\\n```\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = gpt_5_nano.invoke(service_message)"
      ],
      "metadata": {
        "id": "myN27QEmFMWA"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "DZjNRGESGWpx",
        "outputId": "046badde-ee21-4a58-c2c1-7155ed6505fb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Ahoy, dear customer. Please be advised that the warranty does not cover cleaning expenses for yer kitchen, as it appears to be caused by yer own misuse of the blender—namely forgettin' to put the lid on before startin' it. We thank ye for yer understandin', and may ye have fair seas ahead. Fare thee well.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Streaming\n",
        "\n",
        "Most models can stream their output content while it is being generated. By displaying output progressively, streaming significantly improves user experience, particularly for longer responses.\n",
        "\n"
      ],
      "metadata": {
        "id": "iQCEbDQaHIFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Text Streaming\n",
        "Calling `stream()` returns an iterator that yields output chunks as they are produced. You can use a loop to process each chunk in real-time:"
      ],
      "metadata": {
        "id": "Q7qGFxVJMOar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "for chunk in gpt_5_nano.stream(\"Why do parrots have colorful feathers?\"):\n",
        "  await asyncio.sleep(0.1)\n",
        "  print(chunk.text, end=\"\",flush=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UtY9_4h2HJan",
        "outputId": "f605cb5b-5fc5-45f6-8d38-4c683ec401ad"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parrots are colorful mainly because of pigments in their feathers and the way light interacts with feather structure. These colors serve several roles in their life:\n",
            "\n",
            "- Pigments\n",
            "  - Carotenoids from the diet give yellows, oranges, and reds. The amount in the feathers can reflect diet and health.\n",
            "  - Parrots also produce some pigments called psittacofulvins, which add red, orange, and yellow tones and are somewhat unique to parrots.\n",
            "  - Melanin adds blacks and browns and can deepen or dull colors.\n",
            "\n",
            "- Structural colors\n",
            "  - Some blues and iridescent greens come from microscopic feather structures, not from pigments. The way light scatters off these structures creates vivid blues and shimmering effects.\n",
            "\n",
            "- Green coloration\n",
            "  - Green feathers are often a mix: yellow pigments plus a blue structural color, which together look green to the eye.\n",
            "\n",
            "- What colors do for the birds\n",
            "  - Mate attraction and sexual signaling: brighter or more intense colors can indicate good health and fertility to potential mates.\n",
            "  - Health and diet indicators: brighter colors can reflect a diet rich in nutrients like carotenoids.\n",
            "  - Species recognition and social signaling: distinct color patterns help parrots recognize members of their own species and communicate with others.\n",
            "  - Camouflage or display in the canopy: in some habitats, green and dappled patterns help blend in; in others, bright colors help in social interactions and territory defense.\n",
            "\n",
            "- Variation\n",
            "  - Some species (and sometimes the sexes in those species) are more colorful than others. Seasonal changes and breeding season can intensify colors.\n",
            "\n",
            "In short, parrot color comes from a mix of pigments and feather structure, and these colors help them find mates, signal health, recognize friends and rivals, and fit their environment."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streaming Events\n",
        "LangChain chat models can also stream semantic events using `astream_events()`."
      ],
      "metadata": {
        "id": "66zJVTiALSiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async for event in gpt_5_nano.astream_events(\"Hello\"):\n",
        "\n",
        "    if event[\"event\"] == \"on_chat_model_start\":\n",
        "        print(f\"Input: {event['data']['input']}\")\n",
        "\n",
        "    elif event[\"event\"] == \"on_chat_model_stream\":\n",
        "        print(f\"Token: {event['data']['chunk'].text}\")\n",
        "\n",
        "    elif event[\"event\"] == \"on_chat_model_end\":\n",
        "        print(f\"Full message: {event['data']['output'].text}\")\n",
        "\n",
        "    else:\n",
        "        pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UdfQZGGCLJV0",
        "outputId": "c6ff2b2c-4eb6-4943-db38-f42ad5eb2c42"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Hello\n",
            "Token: \n",
            "Token: Hi\n",
            "Token:  there\n",
            "Token: !\n",
            "Token:  How\n",
            "Token:  can\n",
            "Token:  I\n",
            "Token:  help\n",
            "Token:  today\n",
            "Token: ?\n",
            "Token:  I\n",
            "Token:  can\n",
            "Token:  answer\n",
            "Token:  questions\n",
            "Token: ,\n",
            "Token:  help\n",
            "Token:  write\n",
            "Token:  or\n",
            "Token:  edit\n",
            "Token: ,\n",
            "Token:  brainstorm\n",
            "Token:  ideas\n",
            "Token: ,\n",
            "Token:  explain\n",
            "Token:  concepts\n",
            "Token: ,\n",
            "Token:  troubleshoot\n",
            "Token:  issues\n",
            "Token: ,\n",
            "Token:  or\n",
            "Token:  assist\n",
            "Token:  with\n",
            "Token:  coding\n",
            "Token: .\n",
            "Token:  Tell\n",
            "Token:  me\n",
            "Token:  what\n",
            "Token:  you\n",
            "Token: ’d\n",
            "Token:  like\n",
            "Token:  to\n",
            "Token:  do\n",
            "Token: .\n",
            "Token: \n",
            "Token: \n",
            "Token: \n",
            "Full message: Hi there! How can I help today? I can answer questions, help write or edit, brainstorm ideas, explain concepts, troubleshoot issues, or assist with coding. Tell me what you’d like to do.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pxk-_epOLN6o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}